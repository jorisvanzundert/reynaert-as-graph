{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slow Programming & Close Reading #\n",
    "\n",
    "## Introduction ##\n",
    "\n",
    "The rationale of this project is found in what feels to me as a still uncomfortable clash between hermeneutics and distant reading methods. We understand and accept that quantitative approaches can tell us a lot about texts (cf. e.g. <a href=\"#bibref_001\" name=\"backref_bibref_001\" id=\"backref_bibref_001\">Van Dalen &amp; Van Zundert 2007</a>; <a href=\"#bibref_002\" name=\"backref_bibref_002\" id=\"backref_bibref_002\">Kestemont 2011</a>; <a href=\"#bibref_003\" name=\"backref_bibref_003\" id=\"backref_bibref_003\">Ramsay 2012</a>). At the same time well known practitioners of such methods tell us that in the end the patterns that emerge from number crunching and pattern recognition require hermeneutic interpretation to be given meaning (<a href=\"#bibref_004\" name=\"backref_bibref_004\" id=\"backref_bibref_004\">Hayles 2012:38</a>; <a href=\"#bibref_005\" name=\"backref_bibref_005\" id=\"backref_bibref_005\">Underwood &amp; Sellers 2015</a>; <a href=\"#bibref_006\" name=\"backref_bibref_006\" id=\"backref_bibref_006\">Meister 1995</a>). I assert a strong dichotomic predilection in DH research to this matter. It seems necessarily to be one of two. Patterns can be modeled and quantified, but this necessarily results in reductive measures that are lossy of the subtle distinctions that drive hermeneutic interpretation. The gain of this coarse reductiveness is stringent formalization, which ensures computational tractability and therefor the scale and power of the analysis of large numbers: we can measure into corpora without even looking at them with human eyes and intellect. The other option is to apply subtle hermeneutics through close reading a text. This gives the research the power of meticulous interpretation, of precise contextualizing of meaning, of capturing, representing, and interpreting complex heterogeneous knowledge. The loss here however is the power of scale: such hermeneutic precision can not be expressed by simple numbers, such heterogeneity cannot be modeled at scale. Therefor the hermeneutic model is a model of a single or a few texts and a model without computation, it is *only* interpretation. The quantitative model stands in opposition: this counts, and by using the computer it counts eerily fast and into huge corpora—but its understanding of the individual texts in corpora is poor. \n",
    "\n",
    "My conjecture is that the root cause for this perceived dichotomy is the preconception that software must scale—that the usefulness of writing and reading with software, thus the usefulness of code literacy is limited to tasks that are repetitive and thus subject to automation. However, what if we would not focus on scale for a change. What if we apply the values of close reading (attention, detailism .. .. ) to programming? What would formalizing thus—as Slow Programming—in code the process of close reading tells us about a text? This Notebook is a experimental quest towards an answer to that question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reproducible Acts of Scholarly Hermeneutics ###\n",
    "\n",
    "I contend that hermeneutics and interpretation are not mutual exclusive with code. Software and automation *can* be used as reductive methods that limit interpretation or are only crude hermeneutic means on the level of code, but I assert that they need not be. In fact, if anything, code in its form of literate programming (<a href=\"#bibref_007\" name=\"backref_bibref_007\" id=\"backref_bibref_007\">Knuth 1984</a>) is a meticulous precise description of process. Next to that code is also 'just text', just another semiotic system (<a href=\"#bibref_008\" name=\"backref_bibref_008\" id=\"backref_bibref_008\">Marino 2006</a>, <a href=\"#bibref_009\" name=\"backref_bibref_009\" id=\"backref_bibref_009\">Van Zundert 2016</a>). Therefore, if we agree that text is an excellent means for reporting hermeneutic process, code should even be better—because it is 'just' text, but with an edge: it will reproduce process meticulously, as long as we capture the hermeneutic process precisely enough. This is what I want to try to do in this experiment: model each and all hermeneutic choices when reading/editing a text meticulously into code. I will use an Object Oriented approach (<a href=\"#bibref_010\" name=\"backref_bibref_010\" id=\"backref_bibref_010\">Bogost 2009</a>; <a href=\"#bibref_011\" name=\"backref_bibref_011\" id=\"backref_bibref_011\">Object Oriented Programming</a>) to conceptualizing the model and creating the code. I will furthermore hold to these rules when 'Close Reading' a text using code:\n",
    "\n",
    "1. Only direct and indirect speech may be represented as string instances.\n",
    "2. There will be no ‘ghost’ objects or methods (unused program code) during the execution of the program.\n",
    "3. The resulting program should execute without producing Ruby exceptions or runtime errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 1 — Coding the Transcription ##\n",
    "\n",
    "Right after laying down those rules I realized that I missed something. If I want to hold myself to the meticulous precise registration of a reproducible process, I should not for instance transform the 'raw' text by using a text processor (that is: changing the representation by typing and editing the text file), because such requires interpretation action, and all interpretative acts should be modeled or captured in code. It is important in my view that this code is executable computer code. It should express if not possible *all*, at least *as many as possible* of my interpretative and transformative acts. With XML a lot if not most of my scholarly effort, actions, and performance goes unregistered. Between the manuscript and the TEI tag &lt;p&gt; there is a considerable series of scholarly actions that go unregistered and are lost. The aim here is to try to see how much of that scholarly performance can actually be captured in code. Every effort I make should be computationally reproducible. Thus I needed a fourth rule for the project:\n",
    "\n",
    "1. Only direct and indirect speech may be represented as string instances.\n",
    "2. There will be no ‘ghost’ objects or methods (unused program code) during the execution of the program.\n",
    "3. The resulting program should execute without producing Ruby exceptions or runtime errors.\n",
    "4. All scholarly actions should be computationally reproducible \n",
    "\n",
    "So, I can't manually alter or transform the source files I will be using. All scholarly effort shall be expressed in code that guarantees reproducible scholarly actions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up for the Simulation\n",
    "I will be meticulously programming the editorial workflow as a means of code literacy and code scholarship. I understand scholarly code as code that *performs* scholarly *actions*. The digital technology practically available in general for scholars is not as advanced that it may perform physical actions (apart from printing probably). However all other scholarly actions should be mimicked or simulated as closely as possible, and paramount: should be reproducible. Before we can do so some setting up is required. This notebook assumes that you have (access to) a computer with this [Jupyter Notebook](http://jupyter.org/) installed. If not you wouldn't be reading this. The other technical requirements are described as code comments in the next 'cell'. Please follow these requirements guidelines narrowly. This notebook will not work otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Requirements\n",
    "\n",
    "# This notebook requires ImageMagick (an image handling and transformation tool) to be installed.\n",
    "# If you say this at the command line ($>): $> conversion --version\n",
    "# And it gets you an answer similar to this: \n",
    "#    Version: ImageMagick 6.9.3-7 Q16 x86_64 2016-03-27 http://www.imagemagick.org\n",
    "#    Copyright: Copyright (C) 1999-2016 ImageMagick Studio LLC\n",
    "#    License: http://www.imagemagick.org/script/license.php\n",
    "#    Features: Cipher DPC Modules \n",
    "#    Delegates (built-in): bzlib freetype jng jpeg ltdl lzma png tiff xml zlibyou are good to go. \n",
    "# You are good to go\n",
    "# If not see http://www.imagemagick.org/script/binary-releases.php for installation instructions.\n",
    "\n",
    "# This notebook requires Tesseract (an OCR engine) to be installed.\n",
    "# If you say this at the command line ($>): $> tesseract -v\n",
    "# And it gets you an answer similar to this: \n",
    "#    tesseract 3.04.01\n",
    "#    leptonica-1.73\n",
    "#    libgif 4.2.3 : libjpeg 9a : libpng 1.6.21 : libtiff 4.0.6 : zlib 1.2.8 : libwebp 0.5.0 : libopenjp2 2.1.0\n",
    "# you are good to go. \n",
    "# If not see https://github.com/tesseract-ocr/tesseract/wiki for installation instructions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Getting the Manuscript ###\n",
    "\n",
    "Usually the first task when editing is finding, selecting, and perusing one's sources. Obviously the tasks and actions related to getting to the manuscript and digitally photographing it can not be captured in this notebook. Both because computers are severely handicapted for performing such actions—there is a long way to go before computers are actually that actionable—and because of time and economic constraints. The results of such scholarly actions are luckily however in the invaluable care of the Württembergische Landesbibliothek Stuttgart (http://www.wlb-stuttgart.de/), and we can emulate 'going to the library and getting the source' by using the online facsimile bank of the Württembergische Landesbibliothek. \n",
    "\n",
    "For this project I will be using the text of the Middle Dutch fable *Of Reynaert the Fox*. An extend manuscript of this text is found in the so called 'Comburg manuscript' which is in the care of the Würtembergische Landes Bibliothek under the description \"Comburger Handschrift - mittelniederländische Sammelhandschrift - Cod.poet.et phil.fol.22\". Putting 'Comburger' into the general search will get you to the manuscript. We can now emulate going to the library and getting the manuscript with the little script in the second cell followin this paragraph.\n",
    "\n",
    "The first cell imports into the computing environment the libraries—that is: pieces of code not written by me but that we need nevertheless—that are needed for the project. Run this cell like any other to makes sure the libraries are loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "require 'open-uri'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dowloading 00000388.jpg => 388_192v.jpg\n",
      "Dowloading 00000389.jpg => 389_193r.jpg\n",
      "Dowloading 00000390.jpg => 390_193v.jpg\n",
      "Dowloading 00000391.jpg => 391_194r.jpg\n",
      "Dowloading 00000392.jpg => 392_194v.jpg\n",
      "Dowloading 00000393.jpg => 393_195r.jpg\n",
      "Dowloading 00000394.jpg => 394_195v.jpg\n",
      "Dowloading 00000395.jpg => 395_196r.jpg\n",
      "Dowloading 00000396.jpg => 396_196v.jpg\n",
      "Dowloading 00000397.jpg => 397_197r.jpg\n",
      "Dowloading 00000398.jpg => 398_197v.jpg\n",
      "Dowloading 00000399.jpg => 399_198r.jpg\n",
      "Dowloading 00000400.jpg => 400_198v.jpg\n",
      "Dowloading 00000401.jpg => 401_199r.jpg\n",
      "Dowloading 00000402.jpg => 402_199v.jpg\n",
      "Dowloading 00000403.jpg => 403_200r.jpg\n",
      "Dowloading 00000404.jpg => 404_200v.jpg\n",
      "Dowloading 00000405.jpg => 405_201r.jpg\n",
      "Dowloading 00000406.jpg => 406_201v.jpg\n",
      "Dowloading 00000407.jpg => 407_202r.jpg\n",
      "Dowloading 00000408.jpg => 408_202v.jpg\n",
      "Dowloading 00000409.jpg => 409_203r.jpg\n",
      "Dowloading 00000410.jpg => 410_203v.jpg\n",
      "Dowloading 00000411.jpg => 411_204r.jpg\n",
      "Dowloading 00000412.jpg => 412_204v.jpg\n",
      "Dowloading 00000413.jpg => 413_205r.jpg\n",
      "Dowloading 00000414.jpg => 414_205v.jpg\n",
      "Dowloading 00000415.jpg => 415_206r.jpg\n",
      "Dowloading 00000416.jpg => 416_206v.jpg\n",
      "Dowloading 00000417.jpg => 417_207r.jpg\n",
      "Dowloading 00000418.jpg => 418_207v.jpg\n",
      "Dowloading 00000419.jpg => 419_208r.jpg\n",
      "Dowloading 00000420.jpg => 420_208v.jpg\n",
      "Dowloading 00000421.jpg => 421_209r.jpg\n",
      "Dowloading 00000422.jpg => 422_209v.jpg\n",
      "Dowloading 00000423.jpg => 423_210r.jpg\n",
      "Dowloading 00000424.jpg => 424_210v.jpg\n",
      "Dowloading 00000425.jpg => 425_211r.jpg\n",
      "Dowloading 00000426.jpg => 426_211v.jpg\n",
      "Dowloading 00000427.jpg => 427_212r.jpg\n",
      "Dowloading 00000428.jpg => 428_212v.jpg\n",
      "Dowloading 00000429.jpg => 429_213r.jpg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "388..429"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The maximum zoom level images are statically available from this URL:\n",
    "# http://digital.wlb-stuttgart.de/filegroups/combha-m_323970265/max/\n",
    "# The folios 192v-213r coincide with the JPGs 00000388.jpg-00000429.jpg\n",
    "base_url = \"http://digital.wlb-stuttgart.de/filegroups/combha-m_323970265/max/\"\n",
    "\n",
    "side = \"r\"\n",
    "folio_number = 192\n",
    "(388..429).each do |jpgn|\n",
    "\n",
    "  # Instead of jpg order numbers let's add folio numbering to add a bit of\n",
    "  # scholarly atmosphere.\n",
    "  if side.eql?(\"v\")\n",
    "    side=\"r\"\n",
    "    folio_number += 1\n",
    "  else\n",
    "    side=\"v\"\n",
    "  end\n",
    "\n",
    "  folio_name = \"#{jpgn}_#{folio_number}#{side}.jpg\"\n",
    "  puts \"Dowloading #{format(\"%08d\",jpgn)}.jpg => #{folio_name}\"\n",
    "  open( \"./resources/#{folio_name}\", \"wb\" ) do |file|\n",
    "     file << open( \"#{base_url}#{format(\"%08d\",jpgn)}.jpg\" ).read\n",
    "  end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from taking the reader to the library yourself, I don't think we can get the reader/user closer to the source we want to clarify for her. Let's reproduce just one of the facsimile folios here for a taste:\n",
    "\n",
    "<img src=\"resources/388_192v.jpg\" title=\"fol. 192v. Comburger handschrift (WBL Cod.poet.et.phil.fol.22)\" alt=\"Comburger Handschrift, fol. 192v\" width=\"750\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a second extend manuscript of this text, which can be found in the '[Dykse manuscript](http://sammlungen.ulb.uni-muenster.de/hdh/content/pageview/2435423)' currently held by the Universitäts- und Landesbibliothek Münster. The Münster university library offers exellent facsimiles and accompanying [transcriptions](http://repositorium.uni-muenster.de/document/midos/820415cc-9b48-49bf-952d-cfc719dd503c/dycksche-hs_komplett.pdf). The same script above could be adapted to download facsimiles in high detail too. But as this is out of the scope of this notebook I will leave such as an exercise to the reader. (An exercise which is complicated—but certainly not beyond the impossible—by the fact that the Münster university library serves its high resolution facsimiles as composites of so called image [tiles](http://sammlungen.ulb.uni-muenster.de/image/tile/wc/nop/3087/1.0.0/2138975/2/1/2.jpg). But some skillful customization of the last parameters of that URL would get you there.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Emulating) transcribing the source\n",
    "\n",
    "Although [Transkribus](https://transkribus.eu/Transkribus/) promises a lot, at the moment computationally recognizing Middle Dutch manuscript is still a dream. For this reason I am not going to OCR the manuscript, as it is technological infeasible. But I will also not be transcribing the source manually, because the act of transcribing would not be captured by current computer technology and would not be reproducible.<sup><a href=\"#note_001\" name=\"backref_note_001\" id=\"#backref_note_001\">1</a></sup>, and hence I would be violating the fourth self imposed rule.\n",
    "\n",
    "Luckily there is an existing transcription of this manuscript as part of the open access scholarly edition of the *Reynaert* that André Bouwman and Bart Besamusca authored (<a href=\"#bibref_012\" name=\"backref_bibref_012\" id=\"backref_bibref_012\">Bouwman &amp; Besamusca 2009</a>). I will use that transcription as the basis of this project. To have a 'simulation' if you will of the process that would be followed if it were possible to OCR the manuscript, I will download the edition, OCR it, and post correct and interpret the results. All this must be done in a meticulous reproducible way.\n",
    "\n",
    "Let's start by downloading the edition, which is available from http://www.oapen.org/search?identifier=340003:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "#<File:./resources/340003.pdf (closed)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open( \"./resources/340003.pdf\", \"wb\" ) do |file|\n",
    "   file << open( \"http://www.oapen.org/download?type=document&docid=340003\" ).read\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to OCR the text to get an emulation of the act of transcription.<sup><a href=\"#note_002\" name=\"backref_note_002\" id=\"#backref_note_002\">2</a></sup> We only OCR part of the text (page 42–58) which will be quite sufficient for our purposes here. This is the text up to and including the defense that Reynaert's cousin, the badger Grimbeert, delivers in King Noble's court where Reynaert, absent and quite showing his contempt for the court, is indicted. It is a key moment. When Grimbeert finishes his ardent plea, the beheaded body of a hen named Coppe is carried into the court on a bare. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‘Transcribing’ page 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42..58"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = \"./resources/340003.pdf\" # A handle to the PDF document\n",
    "\n",
    "text = \"\" # This will contain the OCR'ed text\n",
    "\n",
    "# Let's notify the user that we're working\n",
    "print \"‘Transcribing’ page \"\n",
    "\n",
    "# We'll do a transcription for each page in the range 42..58\n",
    "(42..58).each do |page_number|\n",
    "  \n",
    "  # Let's notify the user on which page we're working\n",
    "  print \"#{page_number > 42 ? ', ' : ''}#{page_number}\"\n",
    "  \n",
    "  # We 'lift' each page from the pdf by using the command line tool 'convert' and make sure it has sufficient\n",
    "  # resolution (300dpi) and color depth for scanning.\n",
    "  page_image = `convert -depth 8 -density 300 -background white +matte #{file_name}[#{page_number}] tiff:-`\n",
    "  \n",
    "  # We use the 'tesseract' command line tool to OCR each page and add the OCR'ed text to the variable 'text'\n",
    "  IO.popen(\"tesseract stdin stdout txt\", mode='r+') do |io|\n",
    "    io.write page_image\n",
    "    io.close_write\n",
    "    text << io.read\n",
    "  end\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To verify let's check the contents of the first page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXT, TRANSLATION AND NOTES\n",
      "\n",
      " \n",
      "\n",
      "42\n",
      "\n",
      "1O\n",
      "\n",
      "20\n",
      "\n",
      "25\n",
      "\n",
      "Willem die Madocke maecte, [192va,22]\n",
      "daer hi dicken omme waecte,\n",
      "\n",
      "hem vernoyde so haerde\n",
      "\n",
      "dat die avonture van Reynaerde\n",
      "\n",
      "in Dietsche onghemaket bleven\n",
      "\n",
      "— die Arnout niet hevet vulscreven —\n",
      "dat hi die vijte dede soucken\n",
      "\n",
      "ende hise na den Walschen boucken\n",
      "in Dietsche dus hevet begonnen.\n",
      "God moete ons ziere hulpen jonnen!\n",
      "Nu keert hem daertoe mijn zin\n",
      "\n",
      "dat ic bidde in dit beghin\n",
      "\n",
      "beede den dorpren enten doren,\n",
      "\n",
      "ofte si commen daer si horen\n",
      "\n",
      "dese rijme ende dese woort\n",
      "\n",
      "(die hem onnutte sijn ghehoort),\n",
      "\n",
      "dat sise laten onbescaven.\n",
      "\n",
      "Te vele slachten si den raven,\n",
      "\n",
      "die emmer es al even malsch.\n",
      "\n",
      "Si maken sulke rijme valsch,\n",
      "\n",
      "daer si niet meer of ne weten [192vb]\n",
      "dan ic doe hoe dat si heeten\n",
      "\n",
      "die nu in Babilonien leven.\n",
      "\n",
      "Daden si wel, si soudens begheven.\n",
      "Dat en segghic niet dor minen wille.\n",
      "Mijns dichtens ware een ghestille,\n",
      "ne hads mi eene niet ghebeden\n",
      "\n",
      "die in groeter hovesscheden\n",
      "\n",
      "1 AMiddle Dutch story about Madoc has not come down to us, but there are strong indi—\n",
      "cations that a work with this title did at one time exist. Willem’s earlier tale probably told of a\n",
      "dream that Madoc had, as seems to be suggested in Maerlant’s Rijmbijbel (cf. p. 16). Madoc is\n",
      "\n",
      "sometimes considered to have been a story about a seafarer’s adventures.\n",
      "\n",
      "6 It has been suggested that Van den v05 Reynaerde was written by two poets and that Wil—\n",
      "lem completed Arnout’s unﬁnished work. However, serious objections may be raised to this\n",
      "notion of joint authorship. Assuming that the name was not an invention, it seems probable,\n",
      "also in view of the emphatic Walsch—Dietsch (French—Dutch) contrast in the lines before and\n",
      "\n",
      "after the name, that Arnout was a French Renartpoet (cf. p. 15).\n",
      "13 dorpren (‘peasants’) refers to non—courtly persons.\n",
      "\n",
      "PROLOGUE\n",
      "\n",
      " \n",
      "\n",
      "1O\n",
      "\n",
      "20\n",
      "\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "puts text[0..1800]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There, we have a transcription. We see a page number, some line numbers, Middle Dutch text, English footnotes, a header and page numbers of the next page. OCR isn't perfect—as is demonstrated by the number 10 being recognized rather as one and small letter O. However, it gives us the glyphs of the edition at least. \n",
    "\n",
    "From this material we shall build the computational edition of the scholarly edition. But this should not be a digital metaphor of the book. For that the PDF that was downloaded is available, and probably that is good enough for my uses as a reader. This is a point where we could leave off actually. We could say: this is what current computer technology can do, that is: guessing at the glyphs. That's as far as computer science understands text. Or rather we should contend that that is a form and an amount of human knowledge about text that has been computerly expressed. However we can use computer language to upgrade that understanding of the text, by transferring my knowledge about it to computer code. Here we are interested in what it means to transfer the text and knowledge about it to code. What it means to closely read it through code. Maybe even what it means to read text as code? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Proceed to the next chapter](/notebooks/02%20%20From%20Transcription%20to%20Digital%20Text.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "<small>\n",
    "\n",
    "<a href=\"#backref_note_001\" name=\"note_001\" id=\"note_001\">1</a>) Very stricty speaking this is not true. I could have installed a [key logger](https://en.wikipedia.org/wiki/Keystroke_logging \"wikipedia entry on keystroke logging\") and have registered every transcription action thus, probably even including look ups and queries I would have initiated from behind my keyboard. For time constraint reasons this is not feasible for this notebook, however. Also the focus of this notebook is the close reading of the text of the source through code, for which the transcription is a preliminary step that can be simulated in its reproducibility as the following section of the notebook shall demonstrate.\n",
    "\n",
    "<a href=\"#backref_note_002\" name=\"note_002\" id=\"note_002\">2</a>) Digitally informed observers might interrupt here: \"Why not just using some PDF to text converter like [pdftotext](https://en.wikipedia.org/wiki/Pdftotext) and bypassing the probably less precise and CPU intensive OCR process?\" This however would not as faithfully as possible capture and reproduce the act of transcription. Ideally an OCR engine would be able to decently guess at the glyphs of a Medieval manuscript, which is what we mimic or simulate here. However it would never be possible to extract the text from a facsimile image using an algorithm as pdftotext provide. Simply because the image does not contain computer readable text. It only contains pictorial data. \n",
    "</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "<small>\n",
    "\n",
    "<a href=\"#backref_bibref_010\" name=\"bibref_010\" id=\"bibref_010\">Bogost, I., 2009.</a> Wat is Object-Oriented Ontology? A definition for ordinary folk. Ian Bogost. Available at: http://bogost.com/writing/blog/what_is_objectoriented_ontolog/ [Accessed May 18, 2016].\n",
    "\n",
    "<a href=\"#backref_bibref_012\" name=\"bibref_012\" id=\"bibref_012\">Bouwman, A. & Besamusca, B., 2009.</a> *Of Reynaert the Fox: Text and Facing Translation of the Middle Dutch Beast Epic Van den vos Reynaerde*, Amsterdam: Amsterdam University Press. Available at: http://www.oapen.org/search?identifier=340003 [Accessed November 20, 2015].\n",
    "\n",
    "<a href=\"#backref_bibref_001\" name=\"bibref_001\" id=\"bibref_001\">Dalen-Oskam, K. van &amp; Zundert, J.J. van, 2007.</a> Delta for Middle Dutch: Author and copyist distinction in “Walewein.” *Literary and Linguistic Computing*, 22(3), pp.345–362.\n",
    "\n",
    "<a href=\"#backref_bibref_004\" name=\"bibref_004\" id=\"bibref_004\">Hayles, K.N., 2012.</a> How We Think: Digital Media and Contemporary Technogenesis, Chicago (US): University of Chicago Press.\n",
    "\n",
    "<a href=\"#backref_bibref_002\" name=\"bibref_002\" id=\"bibref_002\">Kestemont, M., 2012.</a> *Het gewicht van de auteur. Een onderzoek naar stylometrische auteursherkenning in de Middelnederlandse epiek.* Universiteit Antwerpen, Faculteit Letteren en Wijsbegeerte, Departementen Taal- en Letterkunde.\n",
    "\n",
    "<a href=\"#backref_bibref_007\" name=\"bibref_007\" id=\"bibref_007\">Knuth, D.E., 1984.</a> Literate Programming. The Computer Journal, 27(1), pp.97–111.\n",
    "\n",
    "<a href=\"#backref_bibref_008\" name=\"bibref_008\" id=\"bibref_008\">Marino, M.C., 2006.</a> Critical Code Studies. Electronic Book Review. Available at: http://www.electronicbookreview.com/thread/electropoetics/codology [Accessed January 16, 2015].\n",
    "\n",
    "<a href=\"#backref_bibref_006\" name=\"bibref_006\" id=\"bibref_006\">Meister, J.C., 1995.</a> Consensus ex Machina? Consensus qua Machina! Literary and Linguistic Computing, 10(4), pp.263–270.\n",
    "\n",
    "<a href=\"#backref_bibref_011\" name=\"bibref_011\" id=\"bibref_011\">Object Oriented Programming.</a> Wikipedia, the free encyclopedia. Available at: https://en.wikipedia.org/wiki/Object-oriented_programming [Accessed May 18, 2016].\n",
    "\n",
    "<a href=\"#backref_bibref_003\" name=\"bibref_003\" id=\"bibref_003\">Ramsay, S., 2011.</a> *Reading Machines: Toward an Algorithmic Criticism (Topics in the Digital Humanities)*, Chicago (US): University of Illinois Press.\n",
    "\n",
    "<a href=\"#backref_bibref_005\" name=\"bibref_005\" id=\"bibref_005\">Underwood, T. & Sellers, J., 2015.</a> How Quickly Do Literary Standards Change? Available at: http://figshare.com/articles/How_Quickly_Do_Literary_Standards_Change_/1418394 [Accessed December 16, 2015].\n",
    "\n",
    "<a href=\"#backref_bibref_009\" name=\"bibref_009\" id=\"bibref_009\">Zundert, J.J. van, 2016.</a> Editor, Author, Engineer: Transformation of Authorship in Scholarly Editing? Interdisciplinary Science Reviews, 41(1), [forthcoming].\n",
    "\n",
    "\n",
    "</small>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ruby 2.2.1",
   "language": "ruby",
   "name": "ruby"
  },
  "language_info": {
   "file_extension": ".rb",
   "mimetype": "application/x-ruby",
   "name": "ruby",
   "version": "2.3.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
