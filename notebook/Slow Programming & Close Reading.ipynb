{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slow Programming & Close Reading #\n",
    "\n",
    "The rationale of this project is found in what feels to me as a still uncomfortable clash between hermeneutics and distant reading methods. We understand and accept that quantitative approaches can tell us a lot about texts \\marginpar{ JZ_20160415_1652: Refs. to examples to be added. } At the same time well known practitioners of such methods tell us that in the end the patterns that emerge from number crunching and pattern recognition require hermeneutic interpretation \\marginpar{ JZ_20160415_1657: Refs. to Kirschenbaum, Meister, Ramsay, Underwood etc. } to be given meaning. I assert a strong dichotomic predilection in DH research to this matter. It seems necessarily to be one of two. Patterns can be modeled and quantified, but this necessarily results in reductive measures that are lossy of the subtle distinctions that drive hermeneutic interpretation. The gain of this coarse reductivenes is stringent formalization, which ensures computational tractability and therefor the scale and power of the analysis of large numbers: we can measure into corpora without even looking at them with human eyes and intellect. The other option is to apply subtle hermeneutics through close reading a text. This gives the research the power of meticulous interpretation, of precise contextualizing of meaning, of capturing, representing, and iterpretating complex heterogeneous knowledge. The loss here however is the power of scale: such hermeneutic precision can not be expressed by simple numbers, such heterogeneity cannot be modeled at scale. Therefor the hermeneutic model is a model of a single or a few texts and a model without computation, it is *only* interpretation. The quantitative model stands in opposition: this counts, and by using the computer it counts eerily fast and into huge corpora—but its understanding of the individual texts in corpora is poor. \n",
    "\n",
    "My conjecture is that the root cause for this perceived dichotomy is the preconception that software must scale—that the usefulness of writing and reading with software, thus the usefulness of code literacy is limited to tasks that are repetitive and thus subject to automation. However, what if we would not focus on scale for a change. What if we apply the values of close reading (attention, detailism .. .. ) to programming? What would formalizing thus—as Slow Programming—in code the process of close reading tells us about a text? This Notebook is a experimental quest towards an answer to that question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's experiment ##\n",
    "\n",
    "I contend that hermeneutics and interpretation are not mutual exclusive with code. Softare and automization *can* be used as reductive methods that limit interpretation or are only crude hermeneutic means on the level of code, but i assert that they need not be. In fact, if anything, code in its form of literate programming \\marginpar{ JZ_20160416_1749: Ref. Knuth } is a meticulous precise description of process. Next to that code is also 'just text', just another semiotic system \\marginpar{ JZ_20160416_1751: Ref. Knuth/Sample/Marino? }. Therefore, if we agree that text is an excellent means for reporting hermeneutic process, code should even be better—because it is 'just' text, but with an edge: it will reproduce process meticulously, as long as we capture the hermeneutic process precisely enough. This is what I want to try to do in this experiment: model each and all hermeneutic choices when reading/editing a text meticulousely into code. I will use an Object Oriented approach \\marginpar{ JZ_20160416_1755:  Some Ref. } to devising the model and code. I will furthermore hold to these rules when 'Close Reading' a text using code:\n",
    "\n",
    "1 Only direct and indirect speech may be represented as string instances.\n",
    "2 There will be no ‘ghost’ objects or methods (unused program code) during the execution of the program.\n",
    "3 The resulting program should execute without producing Ruby exceptions or runtime errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## First, let's do no harm ##\n",
    "\n",
    "Right after laying down those rules I realized that if I want to hold myself to the meticulous precise registration of process I should not transform the 'raw' text by using a text processor (that is: changing the representation by typing and editing the text file), because such requires interpretation and all interpretative acts should be modeled or captured in code. So, I can't change the source file I will be using. Two observations now arise…\n",
    "\n",
    "The first is that this file in itself is the result of downloading an edition of the text of the Middledutch Reynaert, and OCR'ing using tesseract. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\\marginpar{ JZ_20160512_1002: refer to the script and the edition } OCR isn't perfect, but it gives us the glyphs of the edition at least, from this we'll build the edition of the edition. But this should not be a digital metaphor of the book. For that the PDF used (open source downloadable here \\marginpar{ JZ_20160512_1005: REF } is available, and probably good enough. Here we are interestd in the question, what is a text when it is transfered (or read?) by code (or as code?). This is where we could leave off actually. We could say: this is what current computer technology can do, that is: guessing at the glyphs. That's as far as computer science understands text. Or rather we should contend that that is a form and an amount of human knowledge about text that has been computerly expressed. However we can use computer language to upgrade that understanding of the text, by transfering my knowledge about it to computer code.\n",
    "\n",
    "It is important in my view that this code is executable computer code. It should express if not possible *all*, at least *as many as possible* of my interpretative and transformative acts. With XML a lot if not most of my scholarly effort, actions, and performance goes unregistered. Between the manuscript and the TEI tag <p> there is a considerable series of scholarly actions that get lost. The aim here is to try to see how much of that scholarly performance can actually be captured in code.\n",
    "\n",
    "Obviously the tasks and actions related to getting to the manuscript and digitally photographing it can not be captured in this notebook. Both because computers are severely handicapt for performing such actions—there is a long way to go before computers are actually that useful—and because of time and economic constraints. The ressults of such scholarly actions are luckily however in the invaluable care of the Württembergische Landesbibliothek Stuttgart (http://www.wlb-stuttgart.de/), and we can emulate 'going to the library and getting the source' by using the online facsimile bank of the Württembergische Landesbibliothek. This we can do with the following little script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require 'open-uri'\n",
    "\n",
    "# The maximum zoom level images are statically available from this URL:\n",
    "# http://digital.wlb-stuttgart.de/filegroups/combha-m_323970265/max/\n",
    "# The folios 192v-213r coincide with the JPGs 00000388.jpg-00000429.jpg\n",
    "base_url = \"http://digital.wlb-stuttgart.de/filegroups/combha-m_323970265/max/\"\n",
    "\n",
    "side = \"r\"\n",
    "folio_number = 192 #429\n",
    "(388..429).each do |jpgn|\n",
    "\n",
    "  # Instead of jpg order numbers let's add folio numbering to add a bit of\n",
    "  # scholarly atmosphere.\n",
    "  if side.eql?(\"v\")\n",
    "    side=\"r\"\n",
    "    folio_number += 1\n",
    "  else\n",
    "    side=\"v\"\n",
    "  end\n",
    "\n",
    "  folio_name = \"#{jpgn}_#{folio_number}#{side}.jpg\"\n",
    "  puts \"Dowloading #{format(\"%08d\",jpgn)}.jpg => #{folio_name}\"\n",
    "  open( \"./folios_as_jpgs/#{folio_name}\", \"wb\" ) do |file|\n",
    "     file << open( \"#{base_url}#{format(\"%08d\",jpgn)}.jpg\" ).read\n",
    "  end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from taking the reader to the library yourself, I don't think we can get the reader/user closer to the source we want to clarify for her"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ruby 2.2.1",
   "language": "ruby",
   "name": "ruby"
  },
  "language_info": {
   "file_extension": ".rb",
   "mimetype": "application/x-ruby",
   "name": "ruby",
   "version": "2.3.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
